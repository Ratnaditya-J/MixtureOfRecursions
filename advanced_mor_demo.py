#!/usr/bin/env python3
"""
Advanced MoR Demo - Showcasing all implemented features

This script demonstrates the advanced Mixture-of-Recursions implementation
including learned thresholds, multi-scale attention, efficiency routing,
and comprehensive analysis tools.
"""

import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent / "src"))

import numpy as np
import torch
from transformers import AutoTokenizer

# Import our advanced MoR components
try:
    from src.analysis.mor_analyzer import create_analyzer
    from src.models.advanced_mor import (
        AdvancedMixtureOfRecursions,
        create_advanced_mor_model,
    )
except ImportError:
    print("Import issue detected - running simplified demo")
    create_advanced_mor_model = None
    create_analyzer = None


def demonstrate_advanced_features():
    """Comprehensive demonstration of advanced MoR features."""

    print("üöÄ ADVANCED MIXTURE-OF-RECURSIONS DEMONSTRATION")
    print("=" * 70)

    # Create tokenizer
    tokenizer = AutoTokenizer.from_pretrained("gpt2")

    # Test texts with varying complexity
    test_texts = [
        "The cat sat on the mat.",  # Simple
        "Quantum mechanics describes the behavior of matter and energy at the molecular, atomic, nuclear, and even smaller microscopic levels.",  # Complex
        "AI research focuses on creating intelligent machines.",  # Medium
        "The implementation of recursive neural architectures enables adaptive computational depth allocation across heterogeneous token sequences.",  # Very complex
        "Hello world!",  # Very simple
    ]

    print("üìù Test Texts:")
    for i, text in enumerate(test_texts, 1):
        print(f"  {i}. {text}")
    print()

    # 1. Demonstrate Basic vs Advanced MoR
    print("üîÑ 1. COMPARING BASIC vs ADVANCED MoR")
    print("-" * 50)

    # Create models
    print("Creating models...")
    basic_model = create_advanced_mor_model("small", use_all_features=False)
    advanced_model = create_advanced_mor_model("small", use_all_features=True)

    print(f"Basic MoR parameters: {sum(p.numel() for p in basic_model.parameters()):,}")
    print(
        f"Advanced MoR parameters: {sum(p.numel() for p in advanced_model.parameters()):,}"
    )
    print()

    # 2. Demonstrate Learned Thresholds
    print("üéØ 2. LEARNED THRESHOLD ROUTING")
    print("-" * 50)

    sample_text = test_texts[1]  # Complex text
    inputs = tokenizer(sample_text, return_tensors="pt", max_length=50, truncation=True)

    with torch.no_grad():
        try:
            outputs = advanced_model(**inputs)
            depths = outputs["recursion_depths"][0]
            aux_outputs = outputs.get("aux_outputs", {})

            tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"][0])

            print(f"Text: {sample_text}")
            print("Token-level analysis:")

            for i, (token, depth) in enumerate(
                zip(tokens[:10], depths[:10])
            ):  # Show first 10 tokens
                complexity = aux_outputs.get("complexity_scores", [torch.zeros(1)])[0]
                if i < len(complexity):
                    comp_score = (
                        complexity[i].item() if hasattr(complexity[i], "item") else 0
                    )
                else:
                    comp_score = 0
                print(f"  {token:>15} ‚Üí depth {depth:.2f}, complexity {comp_score:.3f}")

            print(f"Average recursion depth: {depths.mean().item():.2f}")

            if "computation_log" in outputs:
                print("Computation efficiency:")
                for log in outputs["computation_log"]:
                    print(
                        f"  Depth {log['depth']}: {log['active_tokens']} active tokens ({log['efficiency']:.1%} efficiency)"
                    )

        except Exception as e:
            print(f"Demo encountered issue: {e}")
            print("Continuing with simplified analysis...")

    print()

    # 3. Demonstrate Analysis Tools
    print("üìä 3. COMPREHENSIVE ANALYSIS")
    print("-" * 50)

    try:
        # Create analyzer
        analyzer = create_analyzer(model_type="advanced")

        print("Running recursion pattern analysis...")
        recursion_analysis = analyzer.analyze_recursion_patterns(
            test_texts[:3]
        )  # Analyze first 3 texts

        print("\nRecursion Depth Analysis:")
        for item in recursion_analysis["token_depths"]:
            text_preview = (
                item["text"][:50] + "..." if len(item["text"]) > 50 else item["text"]
            )
            print(f"  Text: {text_preview}")
            print(f"    Avg depth: {item['avg_depth']:.2f}")
            print(f"    Depth range: {item['min_depth']} - {item['max_depth']}")

        print("\nEfficiency Metrics:")
        for item in recursion_analysis["efficiency_metrics"]:
            text_preview = (
                item["text"][:30] + "..." if len(item["text"]) > 30 else item["text"]
            )
            print(f"  {text_preview}: {item['efficiency']:.1%} efficiency")

    except Exception as e:
        print(f"Analysis demo encountered issue: {e}")
        print("This is expected for the demo - full analysis requires trained models.")

    print()

    # 4. Demonstrate Configuration Flexibility
    print("‚öôÔ∏è  4. MODEL CONFIGURATION FLEXIBILITY")
    print("-" * 50)

    configs = ["small", "medium", "large"]
    for config_name in configs:
        try:
            model = create_advanced_mor_model(config_name, use_all_features=True)
            params = sum(p.numel() for p in model.parameters())
            print(f"  {config_name.capitalize()} model: {params:,} parameters")
            print(f"    Hidden size: {model.config.hidden_size}")
            print(f"    Attention heads: {model.config.num_attention_heads}")
            print(f"    Max recursion depth: {model.config.max_recursion_depth}")
            print(f"    Advanced features: ‚úÖ")
        except Exception as e:
            print(f"    {config_name.capitalize()} model: Error creating ({e})")
        print()

    # 5. Feature Summary
    print("üéâ 5. IMPLEMENTED FEATURES SUMMARY")
    print("-" * 50)

    features = [
        "‚úÖ Basic MoR Architecture (recursive layers, adaptive routing)",
        "‚úÖ Learned Threshold Routing (dynamic depth assignment)",
        "‚úÖ Multi-Scale Attention (hierarchical processing)",
        "‚úÖ Efficiency-Aware Routing (computation optimization)",
        "‚úÖ Advanced Caching (adaptive KV caching)",
        "‚úÖ Comprehensive Analysis Tools (depth patterns, efficiency)",
        "‚úÖ Benchmarking Suite (throughput, memory usage)",
        "‚úÖ Token Complexity Correlation Analysis",
        "‚úÖ Configurable Model Sizes (small/medium/large)",
        "‚úÖ Training & Evaluation Scripts",
        "‚úÖ Interactive Jupyter Notebooks",
        "‚úÖ Unified Experiment Runner",
    ]

    for feature in features:
        print(f"  {feature}")

    print()
    print("üéØ NEXT STEPS:")
    print("  1. Train models: python run_mor_experiment.py train --model_size small")
    print(
        "  2. Run evaluation: python run_mor_experiment.py evaluate --model_path results/"
    )
    print("  3. Explore notebooks: jupyter notebook notebooks/")
    print(
        "  4. Analyze patterns: python -c \"from src.analysis import create_analyzer; analyzer = create_analyzer(); print('Analysis ready!')\""
    )
    print()
    print("üöÄ Advanced MoR implementation is ready for research and experimentation!")


if __name__ == "__main__":
    demonstrate_advanced_features()
